{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Answers to coding questions in deep learning\n",
    "Peeter Niidas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Make some preparations\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%tensorflow_version 1.x\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Download either the PHEME5 or PHEME9 dataset.\n",
    "2. Choose any one event from the dataset and load its first 100 JSON files into\n",
    "python memory.\n",
    "3. Extract and load attributes such as source tweets, reply tweets, and favorites\n",
    "count, labels of the source tweets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Get filenames and load data\n",
    "\n",
    "def read_rename_data (dirr, length):\n",
    "    path = dirr\n",
    "    df = pd.DataFrame()\n",
    "    for filename in glob.iglob(path + '**/*.json', recursive=True):\n",
    "        if 'source-tweet' in filename:\n",
    "            i = 1\n",
    "            f = open(filename)\n",
    "            data = json.load(f)\n",
    "            new_row = {'source_tweet': data['text'], 'favorite_count': data['favorite_count'], 'retweet_count':data['retweet_count']}\n",
    "            df = df.append(new_row, ignore_index=True)\n",
    "            f.close()\n",
    "        elif 'reactions' in filename:\n",
    "            f = open(filename)\n",
    "            data = json.load(f)\n",
    "            new_name = 'reply_' + str(i)\n",
    "            df.loc[df.index[-1], new_name] = data['text']\n",
    "            i += 1\n",
    "        if df.shape[0] == length + 1:\n",
    "            df.drop(df.tail(1).index,inplace=True)\n",
    "            return df\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexing.py:1684: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = infer_fill_value(value)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(50, 165)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true = read_rename_data('./data/pheme-rnr-dataset/sydneysiege/non-rumours/', 50)\n",
    "df_true.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 57)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rumors = read_rename_data('./data/pheme-rnr-dataset/sydneysiege/rumours/', 50)\n",
    "df_rumors.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 166)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding labels for data, 1 - truth, 0 - rumor\n",
    "\n",
    "df_true_labelled = df_true.copy()\n",
    "df_true_labelled['Label'] = '1'\n",
    "df_true_labelled.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 58)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rumors_labelled = df_rumors.copy()\n",
    "df_rumors_labelled['Label'] = '0'\n",
    "df_rumors_labelled.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 166)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining labelled datasets\n",
    "\n",
    "df_all_labelled = pd.concat([df_true_labelled, df_rumors_labelled], axis=0)\n",
    "df_all_labelled.reset_index(drop=True)\n",
    "df_all_labelled.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Saving datasets\n",
    "\n",
    "os.chdir('./raw_data/')\n",
    "df_true_labelled.to_csv('raw_true_labelled.csv', index=False)\n",
    "df_rumors_labelled.to_csv('raw_rumors_labelled.csv', index=False)\n",
    "df_all_labelled.to_csv('raw_all_labelled.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 166)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading datasets\n",
    "\n",
    "df_true_labelled = pd.read_csv('raw_true_labelled.csv')\n",
    "df_true_labelled.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 58)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rumors_labelled = pd.read_csv('raw_rumors_labelled.csv')\n",
    "df_rumors_labelled.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 166)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_labelled = pd.read_csv('raw_all_labelled.csv')\n",
    "df_all_labelled.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data cleaning for word2vec conversion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 163)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping numeric features\n",
    "\n",
    "df_cleaning_w2v = df_all_labelled.drop(df_all_labelled.columns[[1, 2, -1]], axis=1)\n",
    "df_cleaning_w2v.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         source_tweet  \\\n0   There are no verses in the Quran about Me want...   \n1   Mosques, synagogues and churches are inviting ...   \n2   #illridewithyou: Viral Aussie solidarity amid ...   \n3   We continue to monitor the situation in #Sydne...   \n4   We love the #illridewithyou initiative. Spread...   \n..                                                ...   \n95  #breaking a number of people appear to have ju...   \n96  RT @australian: Siege situation currently unfo...   \n97  Hostage involved in #SydneySiege texts \"I'm ok...   \n98  #BREAKING: Reports that some of the hostages h...   \n99  Man Haron Monis ID'd as gunman holding captive...   \n\n                                              reply_1  \\\n0   @withnodriver no shit sherlock. are you for re...   \n1   @elronxenu I'm surprised he hasn't been taken ...   \n2                  @MelonRouge I'll ride u and ur mom   \n3                                                 NaN   \n4   @KatSiecris we agree. It's important to rememb...   \n..                                                ...   \n95  @Sema4beach @iamnotshouting @NicholasDole @ABC...   \n96                                                NaN   \n97  @abhishek2928 jusy like terrorists say there i...   \n98  “@SkyNewsAust: #BREAKING: Reports that some of...   \n99        @FoxNews  Really another slimey Islamist! ?   \n\n                                              reply_2  \\\n0   @withnodriver @basznocz Religion doesnt have t...   \n1   @TeamOyeniyi Specifically: guy was on his way ...   \n2   @sirmomonothomo @MelonRouge \\nLol\\nKeep tweeti...   \n3                                                 NaN   \n4   @AmnestyNSW this quote was the first thing I t...   \n..                                                ...   \n95  @kaitjb @iamnotshouting @NicholasDole @ABCNews...   \n96                                                NaN   \n97      @abhishek2928 muslims and terrorists. Doggggs   \n98  @Joseph_M20 @SkyNewsAust http://t.co/QmgulquOb...   \n99  .@FoxNews @kimmie99 \"With ties to ISIS\". Took ...   \n\n                                              reply_3  \\\n0                @fury_jen @TheTweetOfGod blasphemer.   \n1   @TeamOyeniyi So long as he doesn't kill any ho...   \n2     @sirmomonothomo @RT_com truth hurts dogs breath   \n3                                                 NaN   \n4                                                 NaN   \n..                                                ...   \n95  @Sema4beach @kaitjb @NicholasDole @ABCNews24 f...   \n96                                                NaN   \n97  @BBCWorld I think this guy is younger brother ...   \n98                                       @SkyNewsAust   \n99  @FoxNews Why the background dark but its light...   \n\n                                              reply_4  \\\n0    @runitright1 @TheTweetOfGod Sometime also Thor..   \n1   @elronxenu So is he just holed up until the bi...   \n2   @rhu71 @RT_com u look like ur waiting for a cu...   \n3                                                 NaN   \n4                                                 NaN   \n..                                                ...   \n95  @Sema4beach @kaitjb @NicholasDole @ABCNews24  ...   \n96                                                NaN   \n97  @ibedaboss123 yes, to some extent u r correct....   \n98                                       @SkyNewsAust   \n99       @FoxNews ugh, another bearded piece of shit.   \n\n                                              reply_5  \\\n0   @Usairam1 mohamed liked to fuck little aisha. ...   \n1   @abcnewsSydney #sydneysiege Very disturbing ne...   \n2                  @sirmomonothomo #iwon'tridewithyou   \n3                                                 NaN   \n4                                                 NaN   \n..                                                ...   \n95  @iamnotshouting @kaitjb @NicholasDole @ABCNews...   \n96                                                NaN   \n97  @ibedaboss123 we can't point out to any religi...   \n98  @SkyNewsAust @JordanSekulow \\n\\nDefault #Islam...   \n99                      @FoxNews Sniper take him out.   \n\n                                              reply_6  \\\n0   @RStarovich @TheTweetOfGod Hahahha...you're ri...   \n1                 @abcnewsSydney @jarrodmckenna Amen.   \n2            @RT_com Will Abbot shirtfront terrorist?   \n3                                                 NaN   \n4                                                 NaN   \n..                                                ...   \n95                                      @NicholasDole   \n96                                                NaN   \n97  Makes me sad. “@BBCWorld: Hostage involved in ...   \n98  @SkyNewsAust .AUS need to get some IDF HELP/AD...   \n99                              @FoxNews hang his ass   \n\n                                              reply_7  \\\n0   @Usairam1 @basznocz you're kidding they're mak...   \n1   @elronxenu I'm inclined to think outside the s...   \n2                     @RT_com ISIS is Islam is terror   \n3                                                 NaN   \n4                                                 NaN   \n..                                                ...   \n95  @iamnotshouting @kaitjb @NicholasDole @ABCNews...   \n96                                                NaN   \n97  @peeyushmalhotra @BBCWorld thts wht. I guess w...   \n98  @jesuspaddy @minimumwade @skynewsaust I'm tire...   \n99  @FoxNews treated the way they must be treated....   \n\n                                              reply_8  \\\n0   @nselby exactly. I'm holding off RTing this @T...   \n1   @abcnewsSydney Oh cool, just what we need... M...   \n2   @RT_com ISLAM is being hijacked by ISIS.  #ill...   \n3                                                 NaN   \n4                                                 NaN   \n..                                                ...   \n95  @Sema4beach @iamnotshouting @NicholasDole @ABC...   \n96                                                NaN   \n97  @abhishek2928 watch the backladh muslims get i...   \n98  @SkyNewsAust http://t.co/QmgulquObV STOP THE V...   \n99  @FoxNews Gee isn't he cute,quick someone call ...   \n\n                                              reply_9  ... reply_153  \\\n0   @withnodriver @basznocz Our religion is religi...  ...       NaN   \n1   @TeamOyeniyi No, the bigger event is postponed...  ...       NaN   \n2   @RT_com Oh bloody good! The whole world knows ...  ...       NaN   \n3                                                 NaN  ...       NaN   \n4                                                 NaN  ...       NaN   \n..                                                ...  ...       ...   \n95  @Sema4beach @iamnotshouting @NicholasDole @ABC...  ...       NaN   \n96                                                NaN  ...       NaN   \n97  @ibedaboss123 may be correct bt all Muslims r ...  ...       NaN   \n98          @MinimumWade @Joseph_M20 I agree with him  ...       NaN   \n99  @FoxNews There is no Iranian refugee holding h...  ...       NaN   \n\n   reply_154 reply_155 reply_156 reply_157 reply_158 reply_159 reply_160  \\\n0        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n1        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n2        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n3        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n4        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n..       ...       ...       ...       ...       ...       ...       ...   \n95       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n96       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n97       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n98       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n99       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n\n   reply_161 reply_162  \n0        NaN       NaN  \n1        NaN       NaN  \n2        NaN       NaN  \n3        NaN       NaN  \n4        NaN       NaN  \n..       ...       ...  \n95       NaN       NaN  \n96       NaN       NaN  \n97       NaN       NaN  \n98       NaN       NaN  \n99       NaN       NaN  \n\n[100 rows x 163 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source_tweet</th>\n      <th>reply_1</th>\n      <th>reply_2</th>\n      <th>reply_3</th>\n      <th>reply_4</th>\n      <th>reply_5</th>\n      <th>reply_6</th>\n      <th>reply_7</th>\n      <th>reply_8</th>\n      <th>reply_9</th>\n      <th>...</th>\n      <th>reply_153</th>\n      <th>reply_154</th>\n      <th>reply_155</th>\n      <th>reply_156</th>\n      <th>reply_157</th>\n      <th>reply_158</th>\n      <th>reply_159</th>\n      <th>reply_160</th>\n      <th>reply_161</th>\n      <th>reply_162</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>There are no verses in the Quran about Me want...</td>\n      <td>@withnodriver no shit sherlock. are you for re...</td>\n      <td>@withnodriver @basznocz Religion doesnt have t...</td>\n      <td>@fury_jen @TheTweetOfGod blasphemer.</td>\n      <td>@runitright1 @TheTweetOfGod Sometime also Thor..</td>\n      <td>@Usairam1 mohamed liked to fuck little aisha. ...</td>\n      <td>@RStarovich @TheTweetOfGod Hahahha...you're ri...</td>\n      <td>@Usairam1 @basznocz you're kidding they're mak...</td>\n      <td>@nselby exactly. I'm holding off RTing this @T...</td>\n      <td>@withnodriver @basznocz Our religion is religi...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mosques, synagogues and churches are inviting ...</td>\n      <td>@elronxenu I'm surprised he hasn't been taken ...</td>\n      <td>@TeamOyeniyi Specifically: guy was on his way ...</td>\n      <td>@TeamOyeniyi So long as he doesn't kill any ho...</td>\n      <td>@elronxenu So is he just holed up until the bi...</td>\n      <td>@abcnewsSydney #sydneysiege Very disturbing ne...</td>\n      <td>@abcnewsSydney @jarrodmckenna Amen.</td>\n      <td>@elronxenu I'm inclined to think outside the s...</td>\n      <td>@abcnewsSydney Oh cool, just what we need... M...</td>\n      <td>@TeamOyeniyi No, the bigger event is postponed...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>#illridewithyou: Viral Aussie solidarity amid ...</td>\n      <td>@MelonRouge I'll ride u and ur mom</td>\n      <td>@sirmomonothomo @MelonRouge \\nLol\\nKeep tweeti...</td>\n      <td>@sirmomonothomo @RT_com truth hurts dogs breath</td>\n      <td>@rhu71 @RT_com u look like ur waiting for a cu...</td>\n      <td>@sirmomonothomo #iwon'tridewithyou</td>\n      <td>@RT_com Will Abbot shirtfront terrorist?</td>\n      <td>@RT_com ISIS is Islam is terror</td>\n      <td>@RT_com ISLAM is being hijacked by ISIS.  #ill...</td>\n      <td>@RT_com Oh bloody good! The whole world knows ...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We continue to monitor the situation in #Sydne...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>We love the #illridewithyou initiative. Spread...</td>\n      <td>@KatSiecris we agree. It's important to rememb...</td>\n      <td>@AmnestyNSW this quote was the first thing I t...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>#breaking a number of people appear to have ju...</td>\n      <td>@Sema4beach @iamnotshouting @NicholasDole @ABC...</td>\n      <td>@kaitjb @iamnotshouting @NicholasDole @ABCNews...</td>\n      <td>@Sema4beach @kaitjb @NicholasDole @ABCNews24 f...</td>\n      <td>@Sema4beach @kaitjb @NicholasDole @ABCNews24  ...</td>\n      <td>@iamnotshouting @kaitjb @NicholasDole @ABCNews...</td>\n      <td>@NicholasDole</td>\n      <td>@iamnotshouting @kaitjb @NicholasDole @ABCNews...</td>\n      <td>@Sema4beach @iamnotshouting @NicholasDole @ABC...</td>\n      <td>@Sema4beach @iamnotshouting @NicholasDole @ABC...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>RT @australian: Siege situation currently unfo...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>Hostage involved in #SydneySiege texts \"I'm ok...</td>\n      <td>@abhishek2928 jusy like terrorists say there i...</td>\n      <td>@abhishek2928 muslims and terrorists. Doggggs</td>\n      <td>@BBCWorld I think this guy is younger brother ...</td>\n      <td>@ibedaboss123 yes, to some extent u r correct....</td>\n      <td>@ibedaboss123 we can't point out to any religi...</td>\n      <td>Makes me sad. “@BBCWorld: Hostage involved in ...</td>\n      <td>@peeyushmalhotra @BBCWorld thts wht. I guess w...</td>\n      <td>@abhishek2928 watch the backladh muslims get i...</td>\n      <td>@ibedaboss123 may be correct bt all Muslims r ...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>#BREAKING: Reports that some of the hostages h...</td>\n      <td>“@SkyNewsAust: #BREAKING: Reports that some of...</td>\n      <td>@Joseph_M20 @SkyNewsAust http://t.co/QmgulquOb...</td>\n      <td>@SkyNewsAust</td>\n      <td>@SkyNewsAust</td>\n      <td>@SkyNewsAust @JordanSekulow \\n\\nDefault #Islam...</td>\n      <td>@SkyNewsAust .AUS need to get some IDF HELP/AD...</td>\n      <td>@jesuspaddy @minimumwade @skynewsaust I'm tire...</td>\n      <td>@SkyNewsAust http://t.co/QmgulquObV STOP THE V...</td>\n      <td>@MinimumWade @Joseph_M20 I agree with him</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Man Haron Monis ID'd as gunman holding captive...</td>\n      <td>@FoxNews  Really another slimey Islamist! ?</td>\n      <td>.@FoxNews @kimmie99 \"With ties to ISIS\". Took ...</td>\n      <td>@FoxNews Why the background dark but its light...</td>\n      <td>@FoxNews ugh, another bearded piece of shit.</td>\n      <td>@FoxNews Sniper take him out.</td>\n      <td>@FoxNews hang his ass</td>\n      <td>@FoxNews treated the way they must be treated....</td>\n      <td>@FoxNews Gee isn't he cute,quick someone call ...</td>\n      <td>@FoxNews There is no Iranian refugee holding h...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 163 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing URL's, user mentions, hashtags and e-mail addresses\n",
    "\n",
    "def data_cleaning(x):\n",
    "    exclusion_list = ['#', '@']\n",
    "    x = str(x).lower()\n",
    "    cleaned_url = re.sub(r\"https?://\\S+\", \"\", x)\n",
    "    words = str(cleaned_url).split()\n",
    "    cleaned = [word for word in words if all(ch not in word for ch in exclusion_list)]\n",
    "    return ' '.join(cleaned)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df_cleaning_w2v = df_cleaning_w2v.applymap(data_cleaning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Applying lemmatization and tokenizing\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n",
    "\n",
    "def finalise_cleaning(db):\n",
    "    df_out = pd.DataFrame()\n",
    "    def cleaner2(doc):\n",
    "        txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "        if len(txt) > 2:\n",
    "            return ' '.join(txt)\n",
    "    for i in range(db.shape[1]):\n",
    "        brief_clean = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in db.iloc[:, i])\n",
    "        txt = [cleaner2(doc) for doc in nlp.pipe(brief_clean, batch_size=5000, n_process=-1)]\n",
    "        df_part = pd.DataFrame({'reply_'+str(i): txt})\n",
    "        df_out = pd.concat([df_out, df_part], axis=1)\n",
    "        df_out.columns = ['source_tweet' if x=='reply_0' else x for x in df_out.columns]\n",
    "    return df_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up all posts: 246.93 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "df_clean = finalise_cleaning(df_cleaning_w2v)\n",
    "print('Time to clean up all posts: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 163)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Saving cleaned data for time-saving purposes in future implementations\n",
    "\n",
    "df_clean.to_csv('cleaned_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 163)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data from file\n",
    "\n",
    "df_clean = pd.read_csv('cleaned_data.csv')\n",
    "df_clean.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Using bigrams to catch something more\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "#Creating list of words\n",
    "\n",
    "def df_to_wordlist(df):\n",
    "    sent_all = []\n",
    "    for i in range(df.shape[1]):\n",
    "        try:\n",
    "            sent = [row.split() for row in df.iloc[:, i]]\n",
    "        except:\n",
    "            sent = ''\n",
    "        sent_all.extend(sent)\n",
    "    return sent_all"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "wordlist = df_to_wordlist(df_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Creating relevant phrases\n",
    "\n",
    "phrases = Phrases(wordlist, min_count=30, progress_per=10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Transforming according to bigrams detected\n",
    "\n",
    "sentences = bigram[wordlist]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "407"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A little sanity check\n",
    "# Most frequent words\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "word_freq = defaultdict(int)\n",
    "for wordlist in sentences:\n",
    "    for i in wordlist:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "['sydney',\n 'hostage',\n 'cafe',\n 'gunman',\n 'police',\n 'hold',\n 'people',\n 'situation',\n 'siege',\n 'flag']"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and most popular words\n",
    "\n",
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Constructing word2vec model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "16"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     vector_size=300,\n",
    "                     sample=6e-5,\n",
    "                     alpha=0.03,\n",
    "                     min_alpha=0.0007,\n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocabulary table: 0.0 mins\n"
     ]
    }
   ],
   "source": [
    "# Building vocabulary table\n",
    "\n",
    "t = time()\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "print('Time to build vocabulary table: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.0 mins\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "t = time()\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Storing model for future use\n",
    "\n",
    "w2v_model.save(\"word2vec.model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Storing vectors for words\n",
    "\n",
    "from gensim.models import KeyedVectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "word_vectors = w2v_model.wv\n",
    "word_vectors.save(\"word2vec.wordvectors\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading wordvectors\n",
    "\n",
    "w2v_model = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# vector = w2v_model.wv['word']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modifying databases so that every word has it's own cell. Later replacing words with vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 164)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding labels to the dataset\n",
    "\n",
    "labels = df_all_labelled['Label']\n",
    "df_clean_labelled = df_clean.copy()\n",
    "df_clean_labelled = df_clean_labelled.join(labels)\n",
    "df_clean_labelled.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def word_separator(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for i in range(df.shape[0]):\n",
    "        df_line = pd.DataFrame({'ind':[i]})\n",
    "        df_row = pd.DataFrame()\n",
    "        for j in range(df.shape[1]):\n",
    "            name = str(df.columns[j])\n",
    "            try:\n",
    "                sentence = str(df.iloc[:, j][i])\n",
    "            except:\n",
    "                sentence = []\n",
    "            try:\n",
    "                k_max = int(df.iloc[:,j].str.split().str.len().max())\n",
    "            except:\n",
    "                k_max = 1\n",
    "            df_cell = pd.DataFrame()\n",
    "            for k in range(k_max):\n",
    "                subname = name + '_' + str(k)\n",
    "                try:\n",
    "                    words = sentence.split()\n",
    "                except:\n",
    "                    words = []\n",
    "                if k < len(words):\n",
    "                    word = words[k]\n",
    "                else:\n",
    "                    word = ''\n",
    "                df_part = pd.DataFrame({subname: [word]})\n",
    "                df_cell = pd.concat([df_cell, df_part], axis=1)\n",
    "            df_row = pd.concat([df_row, df_cell], axis=1)\n",
    "        df_line = pd.concat([df_line, df_row], axis=1)\n",
    "        df_line.set_index('ind', inplace=True)\n",
    "        df_out = pd.concat([df_out, df_line], axis=0, ignore_index=True)\n",
    "    return df_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to reformat dataframe: 6.85 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "df_all_separate = word_separator(df_clean_labelled)\n",
    "df_all_separate.shape\n",
    "print('Time to reformat dataframe: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 1412)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_separate.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "df_all_separate.to_csv('cleaned_separate_all_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Converting words into vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "def words_2_vec(x):\n",
    "    vector = w2v_model.wv[x]\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'verse' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/8y/yq5dpggj5gq0006wv9sxbx1h0000gn/T/ipykernel_70758/1328354105.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mdf_vectorised_all\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_all_separate\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapplymap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwords_2_vec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Time to vectorise dataframe: {} mins'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mround\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;36m60\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36mapplymap\u001B[0;34m(self, func, na_action, **kwargs)\u001B[0m\n\u001B[1;32m   8819\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_infer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobject\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mignore_na\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mignore_na\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8820\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 8821\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minfer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__finalize__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"applymap\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   8822\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8823\u001B[0m     \u001B[0;31m# ----------------------------------------------------------------------\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[1;32m   8734\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8735\u001B[0m         )\n\u001B[0;32m-> 8736\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   8737\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8738\u001B[0m     def applymap(\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    686\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_raw\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    687\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 688\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_standard\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    689\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    690\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0magg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py\u001B[0m in \u001B[0;36mapply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    810\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    811\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mapply_standard\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 812\u001B[0;31m         \u001B[0mresults\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mres_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_series_generator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    813\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    814\u001B[0m         \u001B[0;31m# wrap results\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py\u001B[0m in \u001B[0;36mapply_series_generator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    826\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseries_gen\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    827\u001B[0m                 \u001B[0;31m# ignore SettingWithCopy here in case the user mutates\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 828\u001B[0;31m                 \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    829\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mABCSeries\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    830\u001B[0m                     \u001B[0;31m# If we have a view on v, we need to make a copy because\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36minfer\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m   8817\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mempty\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8818\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_infer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mignore_na\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mignore_na\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 8819\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_infer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobject\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mignore_na\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mignore_na\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   8820\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8821\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minfer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__finalize__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"applymap\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_libs/lib.pyx\u001B[0m in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m/var/folders/8y/yq5dpggj5gq0006wv9sxbx1h0000gn/T/ipykernel_70758/4176782624.py\u001B[0m in \u001B[0;36mwords_2_vec\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mwords_2_vec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mvector\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mw2v_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwv\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key_or_keys)\u001B[0m\n\u001B[1;32m    402\u001B[0m         \"\"\"\n\u001B[1;32m    403\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey_or_keys\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_KEY_TYPES\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 404\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_vector\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey_or_keys\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    405\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    406\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mvstack\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_vector\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mkey_or_keys\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36mget_vector\u001B[0;34m(self, key, norm)\u001B[0m\n\u001B[1;32m    445\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    446\u001B[0m         \"\"\"\n\u001B[0;32m--> 447\u001B[0;31m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    448\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mnorm\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    449\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfill_norms\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36mget_index\u001B[0;34m(self, key, default)\u001B[0m\n\u001B[1;32m    419\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mdefault\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    420\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 421\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Key '{key}' not present\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    422\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    423\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_vector\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnorm\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: \"Key 'verse' not present\""
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "df_vectorised_all = df_all_separate.applymap(words_2_vec)\n",
    "print('Time to vectorise dataframe: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_vectorised_all.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-99298bfd",
   "language": "python",
   "display_name": "PyCharm (_project)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}