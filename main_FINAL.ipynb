{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Answers to coding questions in deep learning\n",
    "Peeter Niidas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Make some preparations\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%tensorflow_version 1.x\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Download either the PHEME5 or PHEME9 dataset.\n",
    "2. Choose any one event from the dataset and load its first 100 JSON files into\n",
    "python memory.\n",
    "3. Extract and load attributes such as source tweets, reply tweets, and favorites\n",
    "count, labels of the source tweets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Get filenames and load data\n",
    "\n",
    "def read_rename_data (dirr, length):\n",
    "    path = dirr\n",
    "    df = pd.DataFrame()\n",
    "    for filename in glob.iglob(path + '**/*.json', recursive=True):\n",
    "        if 'source-tweet' in filename:\n",
    "            i = 1\n",
    "            f = open(filename)\n",
    "            data = json.load(f)\n",
    "            new_row = {'source_tweet': data['text'], 'favorite_count': data['favorite_count'], 'retweet_count':data['retweet_count']}\n",
    "            df = df.append(new_row, ignore_index=True)\n",
    "            f.close()\n",
    "        elif 'reactions' in filename:\n",
    "            f = open(filename)\n",
    "            data = json.load(f)\n",
    "            new_name = 'reply_' + str(i)\n",
    "            df.loc[df.index[-1], new_name] = data['text']\n",
    "            i += 1\n",
    "        if df.shape[0] == length + 1:\n",
    "            df.drop(df.tail(1).index,inplace=True)\n",
    "            return df\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexing.py:1684: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = infer_fill_value(value)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(50, 165)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true = read_rename_data('./data/pheme-rnr-dataset/sydneysiege/non-rumours/', 50)\n",
    "df_true.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 57)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rumors = read_rename_data('./data/pheme-rnr-dataset/sydneysiege/rumours/', 50)\n",
    "df_rumors.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data cleaning for word2vec conversion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 163)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping numeric features\n",
    "\n",
    "df_cleaning_true_w2v = df_true.drop(df_true.columns[[1, 2]], axis=1)\n",
    "df_cleaning_true_w2v.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 55)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaning_rumors_w2v = df_rumors.drop(df_rumors.columns[[1, 2]], axis=1)\n",
    "df_cleaning_rumors_w2v.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Applying lemmatization and tokenizing\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n",
    "\n",
    "def finalise_cleaning(db):\n",
    "    df_out = pd.DataFrame()\n",
    "    def cleaner2(doc):\n",
    "        txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "        if len(txt) > 2:\n",
    "            return ' '.join(txt)\n",
    "    for i in range(db.shape[1]):\n",
    "        print(i)\n",
    "        brief_clean = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in db.iloc[:, i])\n",
    "        txt = [cleaner2(doc) for doc in nlp.pipe(brief_clean, batch_size=5000, n_process=-1)]\n",
    "        df_part = pd.DataFrame({'reply_'+str(i): txt})\n",
    "        df_out = pd.concat([df_out, df_part], axis=1)\n",
    "        df_out.columns = ['source_tweet' if x=='reply_0' else x for x in df_out.columns]\n",
    "    return df_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "Time to clean up true answers: 250.92 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "df_true_clean = finalise_cleaning(df_cleaning_true_w2v)\n",
    "print('Time to clean up true posts: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 163)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true_clean.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "Time to clean up rumors: 84.6 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "df_rumors_clean = finalise_cleaning(df_cleaning_rumors_w2v)\n",
    "df_rumors_clean.shape\n",
    "print('Time to clean up rumors: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 55)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rumors_clean.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Saving cleaned data for time-saving purposes in future implementations\n",
    "\n",
    "os.chdir('./raw_data/')\n",
    "df_true_clean.to_csv('cleaned_true_data.csv', index=False)\n",
    "df_rumors_clean.to_csv('cleaned_rumors_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading data from file\n",
    "df_true_clean = pd.read_csv('./raw_data/cleaned_true_data.csv')\n",
    "df_true_clean.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_rumors_clean = pd.read_csv('./raw_data/cleaned_rumors_data.csv')\n",
    "df_rumors_clean.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 163)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As for word2vec model we are using true values and rumors together, I will use one common wordlist\n",
    "\n",
    "df_all = pd.concat([df_true_clean, df_rumors_clean], axis=0)\n",
    "df_all.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         source_tweet  \\\n45    break number people appear flee scene sydney...   \n46  rt australian siege situation currently unfold...   \n47  hostage involve sydneysiege text ok mother htt...   \n48    breaking report hostage escape live ch sydne...   \n49  man haron monis id'd gunman hold captive sydne...   \n\n                                              reply_1  \\\n45    sema beach iamnotshoute nicholasdole abcnew ...   \n46                                               None   \n47    abhishek jusy like terrorist difference civi...   \n48    skynewsaust break report hostage escape live...   \n49                             foxnew slimey islamist   \n\n                                              reply_2  \\\n45    kaitjb iamnotshoute nicholasdole abcnews mas...   \n46                                               None   \n47                 abhishek muslims terrorist doggggs   \n48    joseph m skynewsaust http t co qmgulquobv st...   \n49                   foxnew kimmie tie isis take long   \n\n                                              reply_3  \\\n45    sema beach kaitjb nicholasdole abcnews fuck ...   \n46                                               None   \n47             bbcworld think guy young brother kasab   \n48                                               None   \n49                 foxnew background dark light glass   \n\n                                              reply_4  \\\n45    sema beach kaitjb nicholasdole abcnew thank ...   \n46                                               None   \n47    ibedaboss yes extent u r correct u hv accept...   \n48                                               None   \n49                      foxnew ugh bearded piece shit   \n\n                                              reply_5  \\\n45    iamnotshoute kaitjb nicholasdole abcnew yeah...   \n46                                               None   \n47    ibedaboss point religion fr terrorism bt ur ...   \n48    skynewsaust jordansekulow default islamophob...   \n49                                      foxnew sniper   \n\n                                              reply_6  \\\n45                                               None   \n46                                               None   \n47  make sad bbcworld hostage involve sydneysiege ...   \n48    skynewsaust aus need idf help advice deal gu...   \n49                                    foxnew hang ass   \n\n                                              reply_7  \\\n45    iamnotshoute kaitjb nicholasdole abcnew thin...   \n46                                               None   \n47    peeyushmalhotra bbcworld tht wht guess wait ...   \n48    jesuspaddy minimumwade skynewsaust tired ter...   \n49    foxnew treat way treat lesson aussie kill ba...   \n\n                                              reply_8  \\\n45    sema beach iamnotshoute nicholasdole abcnew ...   \n46                                               None   \n47    abhishek watch backladh muslims australia fi...   \n48    skynewsaust http t co qmgulquobv stop violen...   \n49    foxnew gee cute quick hillaryclinton terrori...   \n\n                                              reply_9  ... reply_153  \\\n45    sema beach iamnotshoute nicholasdole abcnew ...  ...       NaN   \n46                                               None  ...       NaN   \n47    ibedaboss correct bt muslim r not terrorist ...  ...       NaN   \n48                         minimumwade joseph m agree  ...       NaN   \n49    foxnew iranian refugee hold hostage australi...  ...       NaN   \n\n   reply_154 reply_155 reply_156 reply_157 reply_158 reply_159 reply_160  \\\n45       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n46       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n47       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n48       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n49       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n\n   reply_161 reply_162  \n45       NaN       NaN  \n46       NaN       NaN  \n47       NaN       NaN  \n48       NaN       NaN  \n49       NaN       NaN  \n\n[5 rows x 163 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source_tweet</th>\n      <th>reply_1</th>\n      <th>reply_2</th>\n      <th>reply_3</th>\n      <th>reply_4</th>\n      <th>reply_5</th>\n      <th>reply_6</th>\n      <th>reply_7</th>\n      <th>reply_8</th>\n      <th>reply_9</th>\n      <th>...</th>\n      <th>reply_153</th>\n      <th>reply_154</th>\n      <th>reply_155</th>\n      <th>reply_156</th>\n      <th>reply_157</th>\n      <th>reply_158</th>\n      <th>reply_159</th>\n      <th>reply_160</th>\n      <th>reply_161</th>\n      <th>reply_162</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>45</th>\n      <td>break number people appear flee scene sydney...</td>\n      <td>sema beach iamnotshoute nicholasdole abcnew ...</td>\n      <td>kaitjb iamnotshoute nicholasdole abcnews mas...</td>\n      <td>sema beach kaitjb nicholasdole abcnews fuck ...</td>\n      <td>sema beach kaitjb nicholasdole abcnew thank ...</td>\n      <td>iamnotshoute kaitjb nicholasdole abcnew yeah...</td>\n      <td>None</td>\n      <td>iamnotshoute kaitjb nicholasdole abcnew thin...</td>\n      <td>sema beach iamnotshoute nicholasdole abcnew ...</td>\n      <td>sema beach iamnotshoute nicholasdole abcnew ...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>rt australian siege situation currently unfold...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>hostage involve sydneysiege text ok mother htt...</td>\n      <td>abhishek jusy like terrorist difference civi...</td>\n      <td>abhishek muslims terrorist doggggs</td>\n      <td>bbcworld think guy young brother kasab</td>\n      <td>ibedaboss yes extent u r correct u hv accept...</td>\n      <td>ibedaboss point religion fr terrorism bt ur ...</td>\n      <td>make sad bbcworld hostage involve sydneysiege ...</td>\n      <td>peeyushmalhotra bbcworld tht wht guess wait ...</td>\n      <td>abhishek watch backladh muslims australia fi...</td>\n      <td>ibedaboss correct bt muslim r not terrorist ...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>breaking report hostage escape live ch sydne...</td>\n      <td>skynewsaust break report hostage escape live...</td>\n      <td>joseph m skynewsaust http t co qmgulquobv st...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>skynewsaust jordansekulow default islamophob...</td>\n      <td>skynewsaust aus need idf help advice deal gu...</td>\n      <td>jesuspaddy minimumwade skynewsaust tired ter...</td>\n      <td>skynewsaust http t co qmgulquobv stop violen...</td>\n      <td>minimumwade joseph m agree</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>man haron monis id'd gunman hold captive sydne...</td>\n      <td>foxnew slimey islamist</td>\n      <td>foxnew kimmie tie isis take long</td>\n      <td>foxnew background dark light glass</td>\n      <td>foxnew ugh bearded piece shit</td>\n      <td>foxnew sniper</td>\n      <td>foxnew hang ass</td>\n      <td>foxnew treat way treat lesson aussie kill ba...</td>\n      <td>foxnew gee cute quick hillaryclinton terrori...</td>\n      <td>foxnew iranian refugee hold hostage australi...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 163 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# Using bigrams to catch something more\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "#Creating list of words\n",
    "\n",
    "def df_to_wordlist(df):\n",
    "    sent_all = []\n",
    "    for i in range(df.shape[1]):\n",
    "        try:\n",
    "            sent = [row.split() for row in df.iloc[:, i]]\n",
    "        except:\n",
    "            sent = ''\n",
    "        sent_all.extend(sent)\n",
    "    return sent_all"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "wordlist = df_to_wordlist(df_all)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# Creating relevant phrases\n",
    "\n",
    "phrases = Phrases(wordlist, min_count=30, progress_per=10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# Transforming according to bigrams detected\n",
    "\n",
    "sentences = bigram[wordlist]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "551"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A little sanity check\n",
    "# Most frequent words\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "word_freq = defaultdict(int)\n",
    "for wordlist in sentences:\n",
    "    for i in wordlist:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "['http_t',\n 'co',\n 'sydney',\n 'sydneysiege',\n 'hostage',\n 'cafe',\n 'gunman',\n 'police',\n 'hold',\n 'break']"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and most popular words\n",
    "\n",
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Constructing word2vec model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "16"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     vector_size=300,\n",
    "                     sample=6e-5,\n",
    "                     alpha=0.03,\n",
    "                     min_alpha=0.0007,\n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocabulary table: 0.0 mins\n"
     ]
    }
   ],
   "source": [
    "# Building vocabulary table\n",
    "\n",
    "t = time()\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "print('Time to build vocabulary table: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.0 mins\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "t = time()\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# Storing model for future use\n",
    "\n",
    "w2v_model.save(\"word2vec.model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Storing vectors for words\n",
    "\n",
    "from gensim.models import KeyedVectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "word_vectors = w2v_model.wv\n",
    "word_vectors.save(\"word2vec.wordvectors\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading wordvectors\n",
    "\n",
    "w2v_model = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# vector = w2v_model.wv['word']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modifying databases so that every word has it's own cell. Later replacing words with vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 164)"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding labels for data, 1 - truth, 0 - rumor\n",
    "\n",
    "df_true_labelled = df_true_clean.copy()\n",
    "df_true_labelled['Label'] = '1'\n",
    "df_true_labelled.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 56)"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rumors_labelled = df_rumors_clean.copy()\n",
    "df_rumors_labelled['Label'] = '0'\n",
    "df_rumors_labelled.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 164)"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining labelled datasets\n",
    "\n",
    "df_all_labelled = pd.concat([df_true_labelled, df_rumors_labelled], axis=0)\n",
    "df_all_labelled.reset_index(drop=True)\n",
    "df_all_labelled.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        source_tweet  \\\n0  verse quran want hold hostage chocolate shop s...   \n1  mosque synagogue church invite public pray syd...   \n2    illridewithyou viral aussie solidarity amid ...   \n3  continue monitor situation sydney closely touc...   \n4  love illridewithyou initiative spread love com...   \n\n                                             reply_1  \\\n0    withnodriver shit sherlock real say decade t...   \n1    elronxenu surprised take hostage outnumber b...   \n2                           melonrouge ride u ur mom   \n3                                               None   \n4    katsiecris agree important remember today ev...   \n\n                                             reply_2  \\\n0    withnodriver basznocz religion not developme...   \n1    teamoyeniyi specifically guy way big event d...   \n2    sirmomonothomo melonrouge lol tweet say earl...   \n3                                               None   \n4    amnestynsw quote thing think hear illridewit...   \n\n                                             reply_3  \\\n0                  fury jen thetweetofgod blasphemer   \n1    teamoyeniyi long kill hostage excellent chan...   \n2        sirmomonothomo rt com truth hurt dog breath   \n3                                               None   \n4                                               None   \n\n                                             reply_4  \\\n0                      runitright thetweetofgod thor   \n1                    elronxenu hole big event happen   \n2    rhu rt com u look like ur wait cum shot ugly...   \n3                                               None   \n4                                               None   \n\n                                             reply_5  \\\n0    usairam mohame like fuck little aisha like y...   \n1    abcnewssydney sydneysiege disturbing news de...   \n2                   sirmomonothomo iwon'tridewithyou   \n3                                               None   \n4                                               None   \n\n                                             reply_6  \\\n0    rstarovich thetweetofgod hahahha right plent...   \n1                   abcnewssydney jarrodmckenna amen   \n2                  rt com abbot shirtfront terrorist   \n3                                               None   \n4                                               None   \n\n                                             reply_7  \\\n0    usairam basznocz kid make hold islamic flag ...   \n1    elronxenu inclined think outside square smel...   \n2                           rt com isis islam terror   \n3                                               None   \n4                                               None   \n\n                                             reply_8  \\\n0    nselby exactly hold rte thetweetofgod end ac...   \n1                abcnewssydney oh cool need religion   \n2            rt com islam hijack isis illridewithyou   \n3                                               None   \n4                                               None   \n\n                                             reply_9  ... reply_154 reply_155  \\\n0    withnodriver basznocz religion religion peac...  ...      None      None   \n1    teamoyeniyi big event postpone foil hole sta...  ...      None      None   \n2    rt com oh bloody good world know isis amp pa...  ...      None      None   \n3                                               None  ...      None      None   \n4                                               None  ...      None      None   \n\n  reply_156 reply_157 reply_158 reply_159 reply_160 reply_161 reply_162 Label  \n0      None      None      None      None      None      None      None     1  \n1      None      None      None      None      None      None      None     1  \n2      None      None      None      None      None      None      None     1  \n3      None      None      None      None      None      None      None     1  \n4      None      None      None      None      None      None      None     1  \n\n[5 rows x 164 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source_tweet</th>\n      <th>reply_1</th>\n      <th>reply_2</th>\n      <th>reply_3</th>\n      <th>reply_4</th>\n      <th>reply_5</th>\n      <th>reply_6</th>\n      <th>reply_7</th>\n      <th>reply_8</th>\n      <th>reply_9</th>\n      <th>...</th>\n      <th>reply_154</th>\n      <th>reply_155</th>\n      <th>reply_156</th>\n      <th>reply_157</th>\n      <th>reply_158</th>\n      <th>reply_159</th>\n      <th>reply_160</th>\n      <th>reply_161</th>\n      <th>reply_162</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>verse quran want hold hostage chocolate shop s...</td>\n      <td>withnodriver shit sherlock real say decade t...</td>\n      <td>withnodriver basznocz religion not developme...</td>\n      <td>fury jen thetweetofgod blasphemer</td>\n      <td>runitright thetweetofgod thor</td>\n      <td>usairam mohame like fuck little aisha like y...</td>\n      <td>rstarovich thetweetofgod hahahha right plent...</td>\n      <td>usairam basznocz kid make hold islamic flag ...</td>\n      <td>nselby exactly hold rte thetweetofgod end ac...</td>\n      <td>withnodriver basznocz religion religion peac...</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mosque synagogue church invite public pray syd...</td>\n      <td>elronxenu surprised take hostage outnumber b...</td>\n      <td>teamoyeniyi specifically guy way big event d...</td>\n      <td>teamoyeniyi long kill hostage excellent chan...</td>\n      <td>elronxenu hole big event happen</td>\n      <td>abcnewssydney sydneysiege disturbing news de...</td>\n      <td>abcnewssydney jarrodmckenna amen</td>\n      <td>elronxenu inclined think outside square smel...</td>\n      <td>abcnewssydney oh cool need religion</td>\n      <td>teamoyeniyi big event postpone foil hole sta...</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>illridewithyou viral aussie solidarity amid ...</td>\n      <td>melonrouge ride u ur mom</td>\n      <td>sirmomonothomo melonrouge lol tweet say earl...</td>\n      <td>sirmomonothomo rt com truth hurt dog breath</td>\n      <td>rhu rt com u look like ur wait cum shot ugly...</td>\n      <td>sirmomonothomo iwon'tridewithyou</td>\n      <td>rt com abbot shirtfront terrorist</td>\n      <td>rt com isis islam terror</td>\n      <td>rt com islam hijack isis illridewithyou</td>\n      <td>rt com oh bloody good world know isis amp pa...</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>continue monitor situation sydney closely touc...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>love illridewithyou initiative spread love com...</td>\n      <td>katsiecris agree important remember today ev...</td>\n      <td>amnestynsw quote thing think hear illridewit...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 164 columns</p>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_labelled.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "def word_separator(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for i in range(df.shape[0]):\n",
    "        print(str(i))\n",
    "        k_max = int(df.iloc[:,i].str.split().str.len().max()) # max No of words in set column\n",
    "        name = str(df.columns[i])\n",
    "        listing = df.iloc[:,i]\n",
    "        df_part = pd.DataFrame()\n",
    "        for j in range(df.shape[1]):\n",
    "            if j < len(listing):\n",
    "                sentence = listing[j]\n",
    "            else:\n",
    "                sentence = []\n",
    "            df_part_0 = pd.DataFrame()\n",
    "            for k in range(k_max):\n",
    "                subname = name + '_' + str(k)\n",
    "                words = str(sentence).split()\n",
    "                if k < len(words):\n",
    "                    word = words[k]\n",
    "                else:\n",
    "                    word = ''\n",
    "                df_part_1 = pd.DataFrame({subname: [word]})\n",
    "                df_part_0 = pd.concat([df_part_0, df_part_1], axis=1)\n",
    "            df_part = pd.concat([df_part, df_part_0], axis=0)\n",
    "        df_out = pd.concat([df_out, df_part], axis=1)\n",
    "    return df_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Time to reformat dataframe: 1.95 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "df_all_separate = word_separator(df_true_labelled)\n",
    "df_all_separate.shape\n",
    "print('Time to reformat dataframe: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "   source_tweet_0  source_tweet_1 source_tweet_2 source_tweet_3  \\\n0           verse           quran           want           hold   \n0          mosque       synagogue         church         invite   \n0  illridewithyou           viral         aussie     solidarity   \n0        continue         monitor      situation         sydney   \n0            love  illridewithyou     initiative         spread   \n\n  source_tweet_4 source_tweet_5 source_tweet_6 source_tweet_7 source_tweet_8  \\\n0        hostage      chocolate           shop         sydney      terrorist   \n0         public           pray         sydney        hostage        tonight   \n0           amid    sydneysiege        islamic          state           link   \n0        closely          touch  juliebishopmp        express        thought   \n0           love     compassion        thought         affect         sydney   \n\n  source_tweet_9  ... reply_49_5 reply_49_6 reply_49_7 reply_49_8 reply_49_9  \\\n0           fuck  ...                                                          \n0    sydneysiege  ...                                                          \n0           http  ...                                                          \n0         prayer  ...                                                          \n0           http  ...                                                          \n\n  reply_49_10 reply_49_11 reply_49_12 reply_49_13 reply_49_14  \n0                                                              \n0                                                              \n0                                                              \n0                                                              \n0                                                              \n\n[5 rows x 760 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source_tweet_0</th>\n      <th>source_tweet_1</th>\n      <th>source_tweet_2</th>\n      <th>source_tweet_3</th>\n      <th>source_tweet_4</th>\n      <th>source_tweet_5</th>\n      <th>source_tweet_6</th>\n      <th>source_tweet_7</th>\n      <th>source_tweet_8</th>\n      <th>source_tweet_9</th>\n      <th>...</th>\n      <th>reply_49_5</th>\n      <th>reply_49_6</th>\n      <th>reply_49_7</th>\n      <th>reply_49_8</th>\n      <th>reply_49_9</th>\n      <th>reply_49_10</th>\n      <th>reply_49_11</th>\n      <th>reply_49_12</th>\n      <th>reply_49_13</th>\n      <th>reply_49_14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>verse</td>\n      <td>quran</td>\n      <td>want</td>\n      <td>hold</td>\n      <td>hostage</td>\n      <td>chocolate</td>\n      <td>shop</td>\n      <td>sydney</td>\n      <td>terrorist</td>\n      <td>fuck</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>mosque</td>\n      <td>synagogue</td>\n      <td>church</td>\n      <td>invite</td>\n      <td>public</td>\n      <td>pray</td>\n      <td>sydney</td>\n      <td>hostage</td>\n      <td>tonight</td>\n      <td>sydneysiege</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>illridewithyou</td>\n      <td>viral</td>\n      <td>aussie</td>\n      <td>solidarity</td>\n      <td>amid</td>\n      <td>sydneysiege</td>\n      <td>islamic</td>\n      <td>state</td>\n      <td>link</td>\n      <td>http</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>continue</td>\n      <td>monitor</td>\n      <td>situation</td>\n      <td>sydney</td>\n      <td>closely</td>\n      <td>touch</td>\n      <td>juliebishopmp</td>\n      <td>express</td>\n      <td>thought</td>\n      <td>prayer</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>love</td>\n      <td>illridewithyou</td>\n      <td>initiative</td>\n      <td>spread</td>\n      <td>love</td>\n      <td>compassion</td>\n      <td>thought</td>\n      <td>affect</td>\n      <td>sydney</td>\n      <td>http</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 760 columns</p>\n</div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_separate.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-99298bfd",
   "language": "python",
   "display_name": "PyCharm (_project)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}